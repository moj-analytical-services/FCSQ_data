{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Children Act Applications\n",
    "\n",
    "### This code includes the following processes:\n",
    "1. Children Act applications data extraction, creating of child level dataset\n",
    "2. Creation of order level dataset\n",
    "3. Creation of application (events) level dataset\n",
    "4. Creation of case starts daatset\n",
    "5. Individual children (annual and quarterly)\n",
    "6. Extaction of High court information and creation of high court flag\n",
    "7. Extration of parties data and counting applicants/respondents in a case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages and set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # for file paths\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import pydbtools as pydb  # see https://github.com/moj-analytical-services/pydbtools\n",
    "import altair as alt  # for plotting, see https://altair-viz.github.io/getting_started/overview.html\n",
    "\n",
    "# few things for viewing dataframes better\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 900)\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some variables to be used throughout the notebook\n",
    "db1 = \"familyman_dev_v2\"\n",
    "snapshot_date = \"2021-11-11\"\n",
    "db2 = \"fcsq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for within athena FCSQ database in the S3 folder\n",
    "fcsq_db_path = f\"s3://alpha-family-data/fcsq_processing/CA_apps/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example code\n",
    "##### Running SQL in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_number</th>\n",
       "      <th>security</th>\n",
       "      <th>second_case_number</th>\n",
       "      <th>parent_case_number</th>\n",
       "      <th>closed</th>\n",
       "      <th>case_model</th>\n",
       "      <th>admin_court_id</th>\n",
       "      <th>date_printed</th>\n",
       "      <th>mojap_file_land_timestamp</th>\n",
       "      <th>mojap_snapshot_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN95D01595</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN95D01598</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN95D01600</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN95D01602</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NN95D01605</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NN95D01606</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NN95D01607</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN95D01608</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NN95D01609</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NN95D01611</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FM1</td>\n",
       "      <td>NN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1625742440</td>\n",
       "      <td>2021-07-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_number  security second_case_number parent_case_number closed case_model admin_court_id date_printed  mojap_file_land_timestamp mojap_snapshot_date\n",
       "0  NN95D01595         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "1  NN95D01598         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "2  NN95D01600         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "3  NN95D01602         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "4  NN95D01605         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "5  NN95D01606         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "6  NN95D01607         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "7  NN95D01608         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "8  NN95D01609         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08\n",
       "9  NN95D01611         5               <NA>               <NA>   <NA>        FM1             NN          NaT                 1625742440          2021-07-08"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we use an f-string which allows variables to be incorporated into the string.\n",
    "# The database contains many snapshots in time. These need to be defined for each table\n",
    "# to avoid returning duplicates\n",
    "\n",
    "# triple quotation marks allow a string to be defined within the quaotation marks even on new lines\n",
    "# makes long sql strings much more readable.\n",
    "# single quotation marks limit the string to a single line.\n",
    "\n",
    "s1 = f\"\"\"\n",
    "select * from {db1}.cases \n",
    "where mojap_snapshot_date = date '{snapshot_date}'\n",
    "limit 10\n",
    "\"\"\"\n",
    "\n",
    "# pydbtools read_sql_query function will return the results of the query into a pandas dataframe\n",
    "simple_results = pydb.read_sql_query(s1)\n",
    "simple_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating temporary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0     10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are creating a temporary table that can be queried later\n",
    "#  from the __temp__ database\n",
    "pydb.create_temp_table(s1, \"case_table\")\n",
    "\n",
    "# Query the temporary table just created. The database to query is called __temp__, this is\n",
    "# an alias for a sandbox database that is created for each user. For more details, see\n",
    "# the pydbtools docs\n",
    "temp_table = pydb.read_sql_query(\"select count(*) as count from __temp__.case_table\")\n",
    "\n",
    "temp_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating tables in Athena\n",
    "###### When creating tables in Athena, the underlying data also needs to be written to a folder in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create path for new table (initial bucket path and sub-folder defined earlier)\n",
    "test_table_s3_path = os.path.join(fcsq_db_path, \"test_table/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create table in Athena FCSQ database, stating the S3 path to store underlying data\n",
    "test_table = f\"\"\"\n",
    "CREATE TABLE {db2}.test_table WITH\n",
    "(\n",
    "    external_location='{test_table_s3_path}'\n",
    ") AS\n",
    "SELECT *\n",
    "FROM __temp__.case_table\n",
    "\"\"\"\n",
    "# execute the SQL query\n",
    "_ = pydb.start_query_execution_and_wait(test_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deleting tables in Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting objs\n"
     ]
    }
   ],
   "source": [
    "# Delete all the underlying data stored within the S3 location\n",
    "if wr.s3.list_objects(test_table_s3_path):\n",
    "    print(\"deleting objs\")\n",
    "    wr.s3.delete_objects(test_table_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# drop the table in Athena\n",
    "drop_test_table = f\"\"\"\n",
    "DROP TABLE {db2}.test_table\n",
    "\"\"\"\n",
    "# execute the SQL query\n",
    "_ = pydb.start_query_execution_and_wait(drop_test_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "InvalidRequestException",
     "evalue": "An error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 7:1: mismatched input 'DROP'. Expecting: '(', <query>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-168cc619c7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This also works but not using old versions of pybd. Note the recommended option is the start_query...wait option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpydb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\"\"DROP TABLE {database2}.test_table\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pydbtools/wrangler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Modifying function {func.__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/awswrangler/_config.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args_raw, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_inject_config_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mavailable_configs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/awswrangler/athena/_read.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, database, ctas_approach, categories, chunksize, s3_output, workgroup, encryption, kms_key, keep_files, ctas_temp_table_name, use_threads, boto3_session, max_cache_seconds, max_cache_query_inspections, max_remote_cache_entries, max_local_cache_entries, data_source, params, s3_additional_kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0ms3_additional_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms3_additional_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m         \u001b[0mboto3_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     )\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/awswrangler/athena/_read.py\u001b[0m in \u001b[0;36m_resolve_query_without_cache\u001b[0;34m(sql, database, data_source, ctas_approach, categories, chunksize, s3_output, workgroup, encryption, kms_key, keep_files, ctas_temp_table_name, use_threads, s3_additional_kwargs, boto3_session)\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0ms3_additional_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms3_additional_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                 \u001b[0mboto3_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboto3_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m             )\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/awswrangler/athena/_read.py\u001b[0m in \u001b[0;36m_resolve_query_without_cache_ctas\u001b[0;34m(sql, database, data_source, s3_output, keep_files, chunksize, categories, encryption, workgroup, kms_key, wg_config, name, use_threads, s3_additional_kwargs, boto3_session)\u001b[0m\n\u001b[1;32m    414\u001b[0m                 \u001b[0;34m\"Is not possible to wrap this query into a CTAS statement. Please use ctas_approach=False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             )\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query_id: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/awswrangler/athena/_read.py\u001b[0m in \u001b[0;36m_resolve_query_without_cache_ctas\u001b[0;34m(sql, database, data_source, s3_output, keep_files, chunksize, categories, encryption, workgroup, kms_key, wg_config, name, use_threads, s3_additional_kwargs, boto3_session)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mencryption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencryption\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mboto3_session\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboto3_session\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         )\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/awswrangler/athena/_utils.py\u001b[0m in \u001b[0;36m_start_query_execution\u001b[0;34m(sql, wg_config, database, data_source, s3_output, workgroup, encryption, kms_key, boto3_session)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mex_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ThrottlingException\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mmax_num_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"QueryExecutionId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/awswrangler/_utils.py\u001b[0m in \u001b[0;36mtry_it\u001b[0;34m(f, ex, ex_code, base, max_num_tries, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_num_tries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mex_code\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"response\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidRequestException\u001b[0m: An error occurred (InvalidRequestException) when calling the StartQueryExecution operation: line 7:1: mismatched input 'DROP'. Expecting: '(', <query>"
     ]
    }
   ],
   "source": [
    "# This also works but not using old versions of pybd. Note the recommended option is the start_query...wait option\n",
    "pydb.read_sql_query(f\"\"\"DROP TABLE {db2}.test_table\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# can also embed the code within the brackets rather than creating as a separate object\n",
    "_ = pydb.start_query_execution_and_wait(f\"\"\"DROP TABLE {db2}.test_table\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Applications and children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Applications - table of all applications, filtered by specific order types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a table with all the applications for CA, codes selected from the order type lookup file.\n",
    "# The cross join unnest function flattens the application values to one row per app type\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "SELECT \n",
    "    e.case_number,\n",
    "    e.receipt_date,\n",
    "    EXTRACT(year FROM e.receipt_date) AS year,\n",
    "    EXTRACT(quarter FROM e.receipt_date) AS quarter,\n",
    "    f.event,\n",
    "    f.field_model,\n",
    "    f.value as all_event_app_types,\n",
    "    TRIM(ord_type) as order_type,\n",
    "    CAST(SUBSTR(CAST(f.event AS varchar),1,3) AS integer) AS court_code\n",
    "  FROM \n",
    "    {db1}.event_fields F\n",
    "    INNER JOIN {db1}.events e\n",
    "      ON f.event = e.event\n",
    "    CROSS JOIN UNNEST(SPLIT(f.value,',')) AS t(ord_type)\n",
    "  WHERE \n",
    "    field_model IN('U22_AT','G50_AT')\n",
    "    AND   TRIM(ord_type) IN (SELECT \n",
    "                               order_type \n",
    "                             FROM \n",
    "                              {db2}.order_type_lookup\n",
    "                             WHERE \n",
    "                               child_act = 'Y')\n",
    "    AND e.error = 'N'\n",
    "    AND f.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "    AND e.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "\"\"\",\n",
    "\n",
    "\"ca_apps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Children (events) - joining the children onto the application using event info where children are recorded on the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only events with children recorded are included. Children not recorded in the value field are dealt with in the following step\n",
    "# As with the previous code above, the cross join unnest flattens the child data to 1 row per child recorded against the application (event)\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "  SELECT \n",
    "    a.*,\n",
    "    f.value children,\n",
    "    TRY_CAST(TRIM(child_role_id) as bigint) child_role_id\n",
    "  FROM \n",
    "    __temp__.ca_apps a\n",
    "    LEFT JOIN {db1}.event_fields f\n",
    "      ON f.event = a.event\n",
    "   CROSS JOIN UNNEST(SPLIT(f.value,',')) AS t(child_role_id)\n",
    "  WHERE f.field_model IN('U22_CH','G50_CH')\n",
    "    AND child_role_id <> ''\n",
    "    AND f.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "\"\"\",\n",
    "\n",
    "\"ca_apps_child_event\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Children (case) - joining the children onto the application data using the roles table where children are not recorded under the event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all events where no children were recorded against the event in the previous table and get children details from the roles/parties tables.\n",
    "# Where there are no children recorded on the event then all children recorded in the case are considered involved in the application - this is not an assumption but based on how Familyman data entry works \n",
    "# Adding date of birth and gender from the parties table\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "  SELECT\n",
    "    a.*,\n",
    "    r.role child_role_id,\n",
    "    p.dob,\n",
    "    p.gender,\n",
    "    r.delete_flag\n",
    "  FROM\n",
    "    __temp__.ca_apps a\n",
    "    JOIN {db1}.roles r \n",
    "      on a.case_number = r.case_number\n",
    "    JOIN {db1}.parties p \n",
    "      on r.party = p.party \n",
    "  WHERE\n",
    "    event not in (SELECT event FROM __temp__.ca_apps_child_event)\n",
    "    AND role_model in ('CHLDC', 'CHLDZ')\n",
    "    AND r.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "    AND p.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "\"\"\",\n",
    "\n",
    "\"ca_apps_child_case\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Appending children from events and children from case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unioning the dataset where child details were taken from the event to the dataset where the child details were taken from the roles table\n",
    "# Gender and DoB of the child are added to the children from the events table\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "  SELECT \n",
    "    a.case_number,\n",
    "    a.receipt_date,\n",
    "    a.year,\n",
    "    a.quarter,\n",
    "    a.event,\n",
    "    a.field_model,\n",
    "    a.court_code,\n",
    "    a.order_type,\n",
    "    l.order_code,\n",
    "    l.order_desc,\n",
    "    a.child_role_id,\n",
    "    p.dob,\n",
    "    p.gender,\n",
    "    r.delete_flag\n",
    "  FROM\n",
    "    __temp__.ca_apps_child_event a\n",
    "    JOIN {db1}.roles r on a.child_role_id = r.role\n",
    "    JOIN {db1}.parties p on r.party = p.party \n",
    "    left join {db2}.order_type_lookup l\n",
    "     on a.order_type = l.order_type\n",
    "  WHERE\n",
    "    r.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "    AND p.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "  UNION ALL\n",
    "  SELECT\n",
    "    a.case_number,\n",
    "    a.receipt_date,\n",
    "    a.year,\n",
    "    a.quarter,\n",
    "    a.event,\n",
    "    a.field_model,\n",
    "    a.court_code,\n",
    "    a.order_type,\n",
    "    l.order_code,\n",
    "    l.order_desc,\n",
    "    a.child_role_id,\n",
    "    a.dob,\n",
    "    a.gender,\n",
    "    a.delete_flag\n",
    "  FROM\n",
    "    __temp__.ca_apps_child_case a\n",
    "    left join {db2}.order_type_lookup l\n",
    "     on a.order_type = l.order_type\n",
    "\"\"\",\n",
    "\n",
    " \"ca_apps_all_children\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Ranking duplicate child/order type data within a case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The apps all children table contains some records with the same order type for the same child in the same case in the same year. \n",
    "# Here we order the cases so that in those cases initial apps are ranked earlier than subsequent apps, and where the ord type is the same the earliest app is ranked highest\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    Floor((date_diff('day',cast(dob as date),cast(receipt_date as date)))/365.25) AS child_age,\n",
    "    substr(case_number, 5,1) as case_type,\n",
    "    ROW_NUMBER() OVER(PARTITION BY year, case_number, child_role_id, order_desc\n",
    "                       ORDER BY case_number, child_role_id, order_desc, field_model DESC, receipt_date ASC) \n",
    "      AS dup_rank\n",
    "FROM \n",
    "   __temp__.\"ca_apps_all_children\"\n",
    "\"\"\",\n",
    "\n",
    "\"ca_apps_dup_rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Children involved in applications \n",
    "#### Children counted for every order type applied for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop table in Athena (if it already exists)\n",
    "_ = pydb.start_query_execution_and_wait(f\"\"\"DROP TABLE {db2}.ca_apps_child\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ealliest record for each duplicate order type per child\n",
    "# Add whether public or private law case type (potentially revisit this as private law may contain adoption cases)\n",
    "\n",
    "#set S3 file path\n",
    "app_child_s3_path = os.path.join(fcsq_db_path, \"app_child/\")\n",
    "# Delete all the underlying data stored within the S3 location\n",
    "if wr.s3.list_objects(app_child_s3_path):\n",
    "    print(\"deleting objs\")\n",
    "    wr.s3.delete_objects(app_child_s3_path)\n",
    "    \n",
    "#Create table in Athena\n",
    "\n",
    "t_child =  f\"\"\"\n",
    "CREATE TABLE {db2}.ca_apps_child WITH\n",
    "(\n",
    "    external_location='{app_child_s3_path}'\n",
    ") AS\n",
    "SELECT\n",
    "    year,\n",
    "    quarter,\n",
    "    case_number,\n",
    "    receipt_date,\n",
    "    event,\n",
    "    field_model,\n",
    "    order_type,\n",
    "    order_code,\n",
    "    order_desc,\n",
    "    child_role_id,\n",
    "    CASE WHEN gender = 1 THEN 'Male'\n",
    "         WHEN gender = 2 THEN 'Female'\n",
    "        ELSE 'Unknown'\n",
    "      end as Gender,\n",
    "    dob,\n",
    "    child_age,\n",
    "    CASE WHEN Child_age is Null\n",
    "          THEN 'Unknown'\n",
    "         WHEN Child_age < 0\n",
    "          THEN 'Other'\n",
    "         WHEN Child_age < 1\n",
    "          THEN '<1 year'\n",
    "         WHEN Child_age<5\n",
    "           THEN '1-4 years'\n",
    "         WHEN Child_age<10\n",
    "          THEN '5-9 years'\n",
    "         WHEN Child_age<15\n",
    "          THEN '10-14 years'\n",
    "         WHEN Child_age<18\n",
    "          THEN '15-17 years'\n",
    "           ELSE 'Other'\n",
    "      END AS Age_band,\n",
    "    court_code,\n",
    "    CASE WHEN order_type in ('CRO','SSC','DCO','OSA','SO','DSO','OC','OCST','ARC','ARST','ESO','XESO','CAO','EPO','XEPO','DEPO','WEP')\n",
    "      OR case_type = 'C' THEN 'C' Else 'P' end as case_type\n",
    "    \n",
    "FROM \n",
    "   __temp__.ca_apps_dup_rank\n",
    "WHERE\n",
    "  dup_rank = 1\n",
    "  and delete_flag = 'N'\n",
    "\"\"\"\n",
    "\n",
    "_ = pydb.start_query_execution_and_wait(t_child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Orders applied for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop table in Athena (if it already exists)\n",
    "_ = pydb.start_query_execution_and_wait(f\"\"\"DROP TABLE {db2}.ca_apps_order_types\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting objs\n"
     ]
    }
   ],
   "source": [
    "# Remove the child ID and group up so we only count an order type within an event once, rather than per child\n",
    "\n",
    "#set S3 file path\n",
    "app_orders_s3_path = os.path.join(fcsq_db_path, \"app_order_types/\")\n",
    "# Delete all the underlying data stored within the S3 location\n",
    "if wr.s3.list_objects(app_orders_s3_path):\n",
    "    print(\"deleting objs\")\n",
    "    wr.s3.delete_objects(app_orders_s3_path)\n",
    "\n",
    "t_orders = f\"\"\"\n",
    "CREATE TABLE {db2}.ca_apps_order_types WITH\n",
    "(\n",
    "    external_location='{app_orders_s3_path}'\n",
    ") AS\n",
    "SELECT \n",
    "  DISTINCT \n",
    "    year,\n",
    "    quarter,\n",
    "    case_number,\n",
    "    case_type,\n",
    "    receipt_date,\n",
    "    event,\n",
    "    court_code,\n",
    "    order_type,\n",
    "    order_code,\n",
    "    order_desc\n",
    "FROM \n",
    "  {db2}.ca_apps_child\n",
    "\"\"\"\n",
    "\n",
    "_ = pydb.start_query_execution_and_wait(t_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Application count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting applications (individual events). Here multiple orders applied for under one event are only counted once\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "SELECT \n",
    "  DISTINCT \n",
    "    year,\n",
    "    quarter,\n",
    "    case_number,\n",
    "    case_type,\n",
    "    receipt_date,\n",
    "    event,\n",
    "    court_code\n",
    "FROM \n",
    "  {db2}.ca_apps_child\n",
    "\"\"\",\n",
    "\n",
    "\"ca_apps_event_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Case count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping just one record per case, and selecting the earliest record\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "SELECT    \n",
    "  case_type,    \n",
    "  case_number,\n",
    "  (MIN(receipt_date)) AS MIN_of_RECEIPT_DATE,\n",
    "  EXTRACT (YEAR FROM (MIN(receipt_date))) AS Year,\n",
    "  EXTRACT (QUARTER FROM (MIN(receipt_date))) AS Quarter\n",
    "FROM \n",
    "  __temp__.ca_apps_event_count\n",
    "GROUP BY \n",
    "  case_type, \n",
    "  case_number\n",
    "\"\"\",\n",
    "\n",
    " \"ca_apps_case_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Individual children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual children by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a count for the number of times an individual child appears within a year, and then selecting the earliest record\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "WITH ca_apps_count_child_yr AS (\n",
    "\n",
    "SELECT    \n",
    "  *,    \n",
    "  ROW_NUMBER() OVER(PARTITION BY year, child_role_id, case_type\n",
    "                       ORDER BY child_role_id, year, receipt_date ASC) \n",
    "      AS child_count_yr\n",
    "FROM \n",
    "  {db2}.ca_apps_child\n",
    "  \n",
    ")\n",
    "  \n",
    "SELECT    \n",
    "  year, \n",
    "  quarter,\n",
    "  case_number,\n",
    "  child_role_id,\n",
    "  gender,\n",
    "  dob,\n",
    "  age_band,\n",
    "  case_type\n",
    "FROM \n",
    "  ca_apps_count_child_yr\n",
    "WHERE\n",
    "  child_count_yr = 1 \n",
    "\"\"\",\n",
    "\n",
    "\"ca_apps_ind_child_yr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual children by quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a count for the number of times an individual child appears within a quarter, and then selecting the earliest record\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "WITH ca_apps_count_child_qtr AS (\n",
    "\n",
    "SELECT    \n",
    "  *,    \n",
    "  ROW_NUMBER() OVER(PARTITION BY year, quarter, child_role_id, case_type\n",
    "                       ORDER BY child_role_id, year, quarter, receipt_date ASC) \n",
    "      AS child_count_qtr\n",
    "FROM \n",
    "  {db2}.ca_apps_child\n",
    "\n",
    ")\n",
    "\n",
    "SELECT    \n",
    "  year, \n",
    "  quarter,\n",
    "  case_number,\n",
    "  child_role_id,\n",
    "  gender,\n",
    "  dob,\n",
    "  age_band,\n",
    "  case_type\n",
    "FROM \n",
    "  ca_apps_count_child_qtr\n",
    "WHERE\n",
    "  child_count_qtr = 1\n",
    "  \n",
    "\"\"\",\n",
    "\n",
    "\"ca_apps_ind_child_qtr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. High Court"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting High Court cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting high court cases listed against the case field table.\n",
    "# there is also a HC event field model (U22_HC). Howver, HMCTS advice that we use the case field as this could be updated during the case (and the event field can't), and so won't be as accurate\n",
    "# There are some duplicate case numbers with different receipt days so we rank and take the earliest\n",
    "# the creating court is taken from the court listed against the U22 (proceedings issued) event\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "WITH high_court_cases AS (\n",
    "\n",
    "SELECT\n",
    "  DISTINCT\n",
    "  c.case_number,\n",
    "  c.value as case_HC_value,\n",
    "  e.creating_court,\n",
    "  CASE WHEN e.creating_court in ('EC','FD','IL','LB','WT','ZC')\n",
    "        THEN 'Central London DFJ'\n",
    "          ELSE 'Not Central London DFJ'\n",
    "    END AS HC_London_Ind,\n",
    "  ROW_NUMBER() OVER(PARTITION BY c.case_number, c.value\n",
    "                       ORDER BY c.case_number, c.value DESC, receipt_date ASC) \n",
    "      AS case_rank\n",
    "FROM\n",
    "  {db1}.case_fields c\n",
    "  LEFT JOIN {db1}.events e\n",
    "    on c.case_number = e.case_number\n",
    "WHERE\n",
    "  (c.field_model = 'FM2C_HC' AND c.value = 'Y') \n",
    "  AND e.event_model = 'U22'\n",
    "  AND e.error = 'N'\n",
    "  AND c.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "  AND e.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "  \n",
    ")\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM \n",
    "  high_court_cases\n",
    "WHERE \n",
    "  case_rank = 1;\n",
    "\n",
    "\"\"\",\n",
    "\n",
    "\"ca_high_court_cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linking High Court cases the the cases starts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link high court cases to original case table\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "SELECT\n",
    "  c.*,\n",
    "  h.case_HC_value,\n",
    "  h.creating_court AS HC_U22_court,\n",
    "  h.HC_London_ind\n",
    "FROM\n",
    "  __temp__.ca_apps_case_count c\n",
    "  LEFT JOIN __temp__.ca_high_court_cases h\n",
    "    ON c.case_number = h.case_number\n",
    "\"\"\",\n",
    "    \n",
    "\"ca_cases_HC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Parties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a table with applicants and respondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out applicant and respondents from the roles table along with gender details from the party table.\n",
    "# currently applicants and respondents from adoption cases are included as there are some adoption cases included within private law but this will be revisited\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "  SELECT\n",
    "    DISTINCT\n",
    "    r.role_model,\n",
    "    CASE WHEN r.role_model in ('APLC','APLZ','APLA')\n",
    "          THEN 'Applicant'\n",
    "         WHEN r.role_model in ('RSPC','RSPZ','RSPA')\n",
    "          THEN 'Respondent'\n",
    "      END AS case_role, \n",
    "    r.role role_id,\n",
    "    r.party as party_id,\n",
    "    r.case_number,\n",
    "    p.gender\n",
    "  FROM\n",
    "    {db1}.roles r \n",
    "    JOIN {db1}.parties p \n",
    "      on r.party = p.party \n",
    "  WHERE\n",
    "    r.role_model in ('APLC','APLZ','APLA','RSPC','RSPZ','RSPA')\n",
    "    AND r.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "    AND p.mojap_snapshot_date = DATE'{snapshot_date}'\n",
    "    AND r.delete_flag = 'N'\n",
    "\"\"\",\n",
    "\n",
    "\"app_resp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linking applicants to case starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When linking we also add a count to how many applicants are recorded on the case\n",
    "# As this is being counted against case starts we are not including applicants in subsequent applications (G50 events)\n",
    "pydb.create_temp_table(\n",
    "f\"\"\"\n",
    "  SELECT\n",
    "    c.year,\n",
    "    c.quarter,\n",
    "    c.MIN_of_RECEIPT_DATE,\n",
    "    c.case_number,\n",
    "    c.case_type,\n",
    "    r.role_model,\n",
    "    r.case_role, \n",
    "    r.role_id,\n",
    "    r.party_id,\n",
    "    r.gender,\n",
    "    ROW_NUMBER() OVER(PARTITION BY c.case_number, case_type\n",
    "                      ORDER BY c.case_number, case_type) \n",
    "      AS applicant_count\n",
    "  FROM\n",
    "    __temp__.ca_apps_case_count c \n",
    "    JOIN __temp__.app_resp r \n",
    "      on c.case_number = r.case_number \n",
    "  WHERE\n",
    "    r.case_role = 'Applicant'\n",
    "\"\"\",\n",
    "\n",
    "\"applicants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linking respondents to case starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When linking we also add a count to how many respondents are recorded on the case\n",
    "# As this is being counted against case starts we are not including respondents in subsequent applications (G50 events)\n",
    "pydb.create_temp_table(\n",
    "f\"\"\"\n",
    "  SELECT\n",
    "    c.year,\n",
    "    c.quarter,\n",
    "    c.MIN_of_RECEIPT_DATE,\n",
    "    c.case_number,\n",
    "    c.case_type,\n",
    "    r.role_model,\n",
    "    r.case_role, \n",
    "    r.role_id,\n",
    "    r.party_id,\n",
    "    r.gender,\n",
    "    ROW_NUMBER() OVER(PARTITION BY c.case_number, case_type\n",
    "                      ORDER BY c.case_number, case_type) \n",
    "      AS respondent_count\n",
    "  FROM\n",
    "    __temp__.ca_apps_case_count c \n",
    "    JOIN __temp__.app_resp r \n",
    "      on c.case_number = r.case_number \n",
    "  WHERE\n",
    "    r.case_role = 'Respondent'\n",
    "\"\"\",\n",
    "\n",
    "\"respondents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting applicants and respondents in each case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linking the count of applicants in a case to the count of respondents in a case\n",
    "pydb.create_temp_table( \n",
    "f\"\"\"\n",
    "  SELECT\n",
    "    c.year,\n",
    "    c.quarter,\n",
    "    c.case_number,\n",
    "    c.case_type,\n",
    "    MAX(a.applicant_count) as No_of_applicants,\n",
    "    MAX(r.respondent_count) as No_of_respondents\n",
    "  FROM\n",
    "    __temp__.ca_apps_case_count c \n",
    "    JOIN __temp__.applicants a \n",
    "      on c.case_number = a.case_number\n",
    "    JOIN __temp__.respondents r\n",
    "      on c.case_number = r.case_number  \n",
    "  GROUP BY\n",
    "    c.year,\n",
    "    c.quarter,\n",
    "    c.case_type,\n",
    "    c.case_number\n",
    "\"\"\",\n",
    "    \n",
    "\"party_count\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
